source(here::here("scripts", "00_libs.R"))
tidy_2afc <- . %>%
map_dfr(read_csv, .id = "source", col_types = cols(.default = "c")) %>%
select(step_cont = stimuli, participant, date, expName, resp_2.keys, resp_3.keys) %>%
mutate(exp = if_else(is.na(resp_2.keys), "stops", "vowels"),
step_cont = str_remove(step_cont, "stim/VC_"),
step_cont = str_remove(step_cont, "stim2/pa"),
step_cont = str_remove(step_cont, "\\+"),
step_cont = str_remove(step_cont, ".wav"),
step_cont = as.numeric(step_cont),
response = case_when(
resp_2.keys == "left"  ~ 0,
resp_2.keys == "right" ~ 1,
resp_3.keys == "left"  ~ 1,
resp_3.keys == "right" ~ 0)) %>%
filter(nchar(as.character(participant)) == 24)
en <- dir_ls(here("data", "raw", "english_2afc"), regexp = "\\.csv$") %>%
tidy_2afc() %>%
mutate(language = "english")
sp <- dir_ls(here("data", "raw", "spanish_2afc"), regexp = "\\.csv$") %>%
tidy_2afc() %>%
mutate(language = "spanish")
fr <- dir_ls(here("data", "raw", "french_2afc"), regexp = "\\.csv$") %>%
tidy_2afc() %>%
mutate(language = "french")
hu <- dir_ls(here("data", "raw", "hungarian_2afc"), regexp = "\\.csv$") %>%
tidy_2afc() %>%
mutate(language = "hungarian")
language_n <- tibble(
en = en$participant %>% unique %>% length,
sp = sp$participant %>% unique %>% length,
hu = hu$participant %>% unique %>% length,
fr = fr$participant %>% unique %>% length) %>%
pivot_longer(cols = everything(), names_to = "language", values_to = "n")
language_ids <- list(
en = en$participant %>% unique,
sp = sp$participant %>% unique,
hu = hu$participant %>% unique,
fr = fr$participant %>% unique
)
en_sp_complete_cases <- en %>%
filter(participant %in% language_ids$sp) %>%
pull(participant) %>% unique
# For RQs 1 and 2 we need participants that did all 3 tasks (sp & en, fr | hu)
# Get fr finishers
all_3_fr <- en_sp_complete_cases %>%
as_tibble() %>%
filter(value %in% language_ids$fr) %>%
pull
all_3_hu <- en_sp_complete_cases %>%
as_tibble() %>%
filter(value %in% language_ids$hu) %>%
pull
attrition <- tibble(
combos = c("en_sp", "en_sp_fr", "en_sp_hu"),
possible = c(length(language_ids$en), length(language_ids$fr), length(language_ids$hu)),
actual = c(length(en_sp_complete_cases), length(all_3_fr), length(all_3_hu)),
attrition = possible - actual
)
ids_needed <- list(
all = c(en_sp_complete_cases, all_3_fr, all_3_hu),
en_sp = en_sp_complete_cases,
en_sp_fr = all_3_fr,
en_sp_hu = all_3_hu
)
saveRDS(ids_needed, here("data", "tidy", "ids_needed.rds"))
lhq_temp <- bind_rows(
read_csv(here("data", "raw", "lhq", "LHQ 3.0 raw result (1).csv")) %>%
select(l1 = 9, l2 = 15, participant = 1, prolific = 2),
read_csv(here("data", "raw", "lhq", "LHQ 3.0 raw result (2).csv")) %>%
select(l1 = 9, l2 = 15, participant = 1, prolific = 2),
read_csv(here("data", "raw", "lhq", "LHQ 3.0 raw result (3).csv")) %>%
select(l1 = 9, l2 = 15, participant = 1, prolific = 2),
read_csv(here("data", "raw", "lhq", "LHQ 3.0 raw result (5).csv")) %>%
select(l1 = 9, l2 = 15, participant = 1, prolific = 2),
read_csv(here("data", "raw", "lhq", "LHQ 3.0 raw result (6).csv")) %>%
select(l1 = 9, l2 = 15, participant = 1, prolific = 2))
lhq_main <- lhq_temp %>%
filter(nchar(as.character(participant)) == 24)
lhq_sub <- lhq_temp %>%
filter(nchar(as.character(participant)) == 5)
missing_ids <- read_csv(here("data", "raw", "lhq", "prolifictolhq.csv")) %>%
janitor::clean_names() %>%
select(participant = 2, prolific_id = 1) %>%
left_join(., lhq_sub, by = "participant") %>%
select(l1, l2, participant, prolific = prolific_id)
lhq <- bind_rows(lhq_main, missing_ids) %>%
filter(nchar(as.character(prolific)) == 24) %>%
select(l1, l2, participant = prolific)
sum(!(ids_needed$all %in% lhq$participant))
sum(!(ids_needed$en_sp %in% lhq$participant))
sum(!(ids_needed$en_sp_hu %in% lhq$participant))
sum(!(ids_needed$en_sp_fr %in% lhq$participant))
no_id <- c("5f00962ef7b0241ae371d912","5f3050933b5a04118e4a4f73","5f6916f985575a0f22ec8f69")
no_id_df <- bind_rows(en, sp, fr, hu) %>%
select(participant, exp, language, step_cont, response) %>%
filter(!is.na(response), participant %in% ids_needed$all) %>%
filter(participant == "5f00962ef7b0241ae371d912"| participant == "5f3050933b5a04118e4a4f73"| participant == "5f6916f985575a0f22ec8f69") %>%
mutate(l1 = "Spanish", l2 = "English")
all_data <- bind_rows(en, sp, fr, hu) %>%
select(participant, exp, language, step_cont, response) %>%
filter(!is.na(response), participant %in% ids_needed$all) %>%
left_join(., lhq, by = "participant") %>%
filter(!(participant %in% no_id)) %>%
rbind(., no_id_df) %>%
write_csv(here("data", "tidy", "all_2afc.csv"))
all_2afc_long <- read_csv(here("data", "tidy", "all_2afc.csv")) %>%
filter(!is.na(l1)) %>% # filter out 3 particpants with no L1/L2 info
mutate(step_std = (step_cont - mean(step_cont)) / sd(step_cont))
# Preprocessing for eLog omnibus model
all_2afc_wide <- all_2afc_long %>%
group_by(., participant, exp, l1, language, step_std) %>%
mutate(rep_n = seq_along(step_std)) %>%
summarise(., n = length(unique(rep_n)),
resp_1 = sum(response),
resp_0 = n - resp_1,
prop = resp_1 / n,
eLog = log((resp_1 + 0.5) / (n - resp_1 + 0.5)),
wts = 1 / (resp_1 + 0.5) + 1 / (n - resp_1 + 0.5)) %>%
mutate(., bin = seq_along(step_std)) %>%
ungroup(.)
ids_needed <- readRDS(here("data", "tidy", "ids_needed.rds"))
# -----------------------------------------------------------------------------
fit_one_mod <- function(data, elog = FALSE) {
if (elog == FALSE) {
mod <- glm(
cbind(resp_1, resp_0) ~ step_std,
data = data,
family = binomial(link = "logit")
)
return(mod)
} else {
mod <- lm(
eLog ~ step_std,
weights = wts,
data = data
)
return(mod)
}
}
# Nest data and fit glm to every participant in every session
# Generates warnings because some participants have flat sigmoids
ind_dfs <- all_2afc_wide %>%
group_by(participant, exp, language) %>%
nest() %>%
mutate(mod = map(data, fit_one_mod, elog = FALSE)) %>%
mutate(tidy = map(mod, tidy))
# Clean up and calculate crossovers
co_df <- ind_dfs %>%
unnest(tidy) %>%
select(-c('std.error', 'statistic', 'p.value')) %>%
pivot_wider(names_from = "term", values_from = "estimate") %>%
select(participant:language, intercept = `(Intercept)`, slope = step_std) %>%
mutate(co = intercept / slope * -1) %>%
left_join(., all_2afc_wide %>% select(participant, l1) %>% distinct,
by = "participant") %>%
ungroup()
saveRDS(co_df, here("data", "tidy", "co_all_tidy.rds"))
# -----------------------------------------------------------------------------
# Tidy lextale -------------------------------------------------------------------
#
# Last update: 2021-03-27
# Describe what this script does here.
#
# -----------------------------------------------------------------------------
# Source libs, data, and models -----------------------------------------------
source(here::here("scripts", "00_libs.R"))
source(here("scripts", "01_tidy2afc.R"))
source(here("scripts", "02_load_data.R"))
source(here("scripts", "03_crossover.R"))
# -----------------------------------------------------------------------------
score_lextale <- function(
n_real = NULL,
n_nonse = NULL,
n_real_correct = NULL,
n_nonse_correct = NULL,
n_nonse_incorrect = NULL) {
if (is.null(n_nonse_incorrect)) {
avg_real <-  (n_real_correct / n_real * 100)
avg_nonse <- (n_nonse_correct / n_nonse * 100)
val <- (avg_real + avg_nonse) / 2
} else {
val <- n_real_correct - (2 * n_nonse_incorrect)
}
return(val)
}
# Load english lextale data
english_lextale <- read_csv("data/raw/lextale_english.csv")
# Load and tidy spanish lextale data
lextale_spanish_raw = dir_ls(here("data/raw", "lextale"), regexp = "\\.csv$") %>%
map_dfr(read_csv, .id = "source", col_types = cols(.default = "c")) %>%
filter(!is.na(key_resp_lextale_trial.keys)) %>%
mutate(., response = `key_resp_lextale_trial.keys`,
is_correct = key_resp_lextale_trial.corr,
is_incorrect = if_else(is_correct == 0, 1, 0),
is_real = case_when(
response == 1 & is_correct == 1 ~ "real",
response == 1 & is_correct == 0 ~ "nonse",
response == 0 & is_correct == 1 ~ "nonse",
response == 0 & is_correct == 0 ~ "real"),
real_correct    = if_else(is_real == "real"  & is_correct == 1, 1, 0),
real_incorrect  = if_else(is_real == "real"  & is_correct == 0, 1, 0),
nonse_correct   = if_else(is_real == "nonse" & is_correct == 1, 1, 0),
nonse_incorrect = if_else(is_real == "nonse" & is_correct == 0, 1, 0))
# calculate scores, both traditional and new - remove any duplicates - filter
# for prolific participants only
spanish_lextale = lextale_spanish_raw %>%
group_by(participant, date) %>%
summarize(totals = n(),
real_correct = sum(real_correct),
real_incorrect = sum(real_incorrect),
nonse_correct = sum(nonse_correct),
nonse_incorrect = sum(nonse_incorrect)) %>%
mutate(n_real = real_correct + real_incorrect,
n_nonse = nonse_correct + nonse_incorrect,
n = n_real + n_nonse,
lextale_avg = score_lextale(
n_real = n_real,
n_nonse = n_nonse,
n_real_correct = real_correct,
n_nonse_correct = nonse_correct),
lextale_tra = score_lextale(
n_real_correct = real_correct,
n_nonse_incorrect = nonse_incorrect))
spanish_lextale = spanish_lextale %>%
.[!duplicated(spanish_lextale$participant), ]
spanish_bind = spanish_lextale %>%
filter(nchar(as.character(participant)) == 24) %>%
select(participant, lextale_avg) %>%
rename(score = lextale_avg)
all_lextale = rbind(spanish_bind, english_lextale)
spanish_bind2 = spanish_bind %>%
mutate(L1 = "English")
desc_prof = english_lextale %>%
mutate(L1 = "Spanish") %>%
rbind(spanish_bind2) %>%
filter((participant %in% all_data$participant)) %>%
group_by(L1) %>%
summarise(`Mean LEXtale Score` = mean(score), `SD` = sd(score), n = n())
desc_prof_plot = english_lextale %>%
mutate(L1 = "Spanish") %>%
rbind(spanish_bind2) %>%
filter((participant %in% all_data$participant)) %>%
filter(score > 60)
# join lextale data from both langauges with co_df
co_df_prof = co_df %>%
left_join(all_lextale, by = "participant")
co_df_prof = co_df %>%
left_join(all_lextale, by = "participant") %>%
write_csv(here("data", "tidy", "co_df_prof.csv"))
htmltools
remove.packages("htmltools")
update.packages("htmltools")
update.packages("htmltools")
